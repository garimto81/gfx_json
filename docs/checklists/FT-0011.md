# FT-0011: TDD Checklist

## 문서 정보

| 항목 | 내용 |
|------|------|
| PRD | [FT-0011](../../docs/unified/prds/FT/FT-0011-nas-supabase-sync-optimization.md) |
| 설계 문서 | [DESIGN.md](../DESIGN.md) |
| 브랜치 | `feat/FT-0011-nas-supabase-sync` |
| 상태 | **Complete** |
| 커버리지 | **88%** |

---

## 진행 현황

| 단계 | 완료 | 총 | 진행률 |
|------|------|-----|--------|
| Phase 1: BatchQueue | 6 | 6 | 100% |
| Phase 2: LocalQueue | 5 | 5 | 100% |
| Phase 3: FileWatcher | 5 | 5 | 100% |
| Phase 4: SyncService | 6 | 6 | 100% |
| Phase 5: Integration | 3 | 3 | 100% |
| **총계** | **25** | **25** | **100%** |

---

## Phase 1: BatchQueue (TDD)

**파일**: `src/sync_agent/batch_queue.py`
**테스트**: `tests/test_batch_queue.py`

### 1.1 기본 기능

- [ ] **RED**: `test_add_single_record` - 단일 레코드 추가
  ```python
  async def test_add_single_record():
      queue = BatchQueue(max_size=500)
      result = await queue.add({"id": 1})
      assert result is None  # 플러시 안됨
      assert queue.pending_count == 1
  ```

- [ ] **RED**: `test_flush_on_max_size` - max_size 도달 시 자동 플러시
  ```python
  async def test_flush_on_max_size():
      queue = BatchQueue(max_size=3)
      await queue.add({"id": 1})
      await queue.add({"id": 2})
      result = await queue.add({"id": 3})  # 3번째에서 플러시
      assert len(result) == 3
      assert queue.pending_count == 0
  ```

- [ ] **RED**: `test_manual_flush` - 수동 플러시
  ```python
  async def test_manual_flush():
      queue = BatchQueue()
      await queue.add({"id": 1})
      result = await queue.flush()
      assert len(result) == 1
      assert queue.pending_count == 0
  ```

### 1.2 시간 기반 플러시

- [ ] **RED**: `test_flush_on_interval` - 시간 경과 시 자동 플러시
  ```python
  async def test_flush_on_interval():
      queue = BatchQueue(flush_interval=0.1)
      await queue.add({"id": 1})
      await asyncio.sleep(0.15)  # interval 경과
      result = await queue.add({"id": 2})  # 이 시점에 플러시
      assert len(result) == 2
  ```

### 1.3 동시성

- [ ] **RED**: `test_concurrent_add` - 동시 추가 안전성
  ```python
  async def test_concurrent_add():
      queue = BatchQueue(max_size=100)
      tasks = [queue.add({"id": i}) for i in range(50)]
      await asyncio.gather(*tasks)
      assert queue.pending_count == 50
  ```

- [ ] **RED**: `test_empty_flush` - 빈 큐 플러시
  ```python
  async def test_empty_flush():
      queue = BatchQueue()
      result = await queue.flush()
      assert result == []
  ```

---

## Phase 2: LocalQueue (TDD)

**파일**: `src/sync_agent/local_queue.py`
**테스트**: `tests/test_local_queue.py`

### 2.1 기본 CRUD

- [ ] **RED**: `test_enqueue` - 큐에 추가
  ```python
  async def test_enqueue(local_queue):
      await local_queue.enqueue({"file_hash": "abc"}, "/path/to/file.json")
      count = await local_queue.get_pending_count()
      assert count == 1
  ```

- [ ] **RED**: `test_dequeue_batch` - 배치 가져오기
  ```python
  async def test_dequeue_batch(local_queue):
      for i in range(10):
          await local_queue.enqueue({"id": i}, f"/path/{i}.json")
      batch = await local_queue.dequeue_batch(limit=5)
      assert len(batch) == 5
  ```

- [ ] **RED**: `test_mark_completed` - 완료 처리
  ```python
  async def test_mark_completed(local_queue):
      await local_queue.enqueue({"id": 1}, "/path/1.json")
      batch = await local_queue.dequeue_batch(limit=1)
      await local_queue.mark_completed([batch[0]["_queue_id"]])
      count = await local_queue.get_pending_count()
      assert count == 0
  ```

### 2.2 재시도 관리

- [ ] **RED**: `test_mark_failed_increments_retry` - 실패 시 retry_count 증가
  ```python
  async def test_mark_failed_increments_retry(local_queue):
      await local_queue.enqueue({"id": 1}, "/path/1.json")
      batch = await local_queue.dequeue_batch(limit=1)
      await local_queue.mark_failed(batch[0]["_queue_id"])
      # retry_count가 증가했는지 확인
      batch2 = await local_queue.dequeue_batch(limit=1)
      assert batch2[0]["_retry_count"] == 1
  ```

### 2.3 영속성

- [ ] **RED**: `test_persistence` - 재시작 후 데이터 유지
  ```python
  async def test_persistence(tmp_path):
      db_path = tmp_path / "queue.db"
      queue1 = LocalQueue(str(db_path))
      await queue1.enqueue({"id": 1}, "/path/1.json")

      # 새 인스턴스로 재연결
      queue2 = LocalQueue(str(db_path))
      count = await queue2.get_pending_count()
      assert count == 1
  ```

---

## Phase 3: FileWatcher (TDD)

**파일**: `src/sync_agent/file_watcher.py`
**테스트**: `tests/test_file_watcher.py`

### 3.1 이벤트 감지

- [ ] **RED**: `test_detect_file_created` - 파일 생성 감지
  ```python
  async def test_detect_file_created(tmp_path):
      created_files = []

      async def on_created(path):
          created_files.append(path)

      watcher = WatchfilesWatcher(
          watch_path=str(tmp_path),
          on_created=on_created,
          on_modified=lambda p: None,
      )

      task = asyncio.create_task(watcher.start())
      await asyncio.sleep(0.1)

      (tmp_path / "test.json").write_text("{}")
      await asyncio.sleep(0.5)

      await watcher.stop()
      assert len(created_files) == 1
  ```

- [ ] **RED**: `test_detect_file_modified` - 파일 수정 감지
  ```python
  async def test_detect_file_modified(tmp_path):
      modified_files = []
      test_file = tmp_path / "test.json"
      test_file.write_text("{}")

      async def on_modified(path):
          modified_files.append(path)

      watcher = WatchfilesWatcher(
          watch_path=str(tmp_path),
          on_created=lambda p: None,
          on_modified=on_modified,
      )

      task = asyncio.create_task(watcher.start())
      await asyncio.sleep(0.1)

      test_file.write_text('{"updated": true}')
      await asyncio.sleep(0.5)

      await watcher.stop()
      assert len(modified_files) >= 1
  ```

### 3.2 필터링

- [ ] **RED**: `test_pattern_filter` - JSON 파일만 감지
  ```python
  async def test_pattern_filter(tmp_path):
      created_files = []

      watcher = WatchfilesWatcher(
          watch_path=str(tmp_path),
          on_created=lambda p: created_files.append(p),
          on_modified=lambda p: None,
          file_pattern="*.json",
      )

      task = asyncio.create_task(watcher.start())
      await asyncio.sleep(0.1)

      (tmp_path / "test.txt").write_text("text")   # 무시
      (tmp_path / "test.json").write_text("{}")    # 감지
      await asyncio.sleep(0.5)

      await watcher.stop()
      assert len(created_files) == 1
      assert "test.json" in created_files[0]
  ```

### 3.3 시작/중지

- [ ] **RED**: `test_start_stop` - 정상 시작/중지
  ```python
  async def test_start_stop(tmp_path):
      watcher = WatchfilesWatcher(
          watch_path=str(tmp_path),
          on_created=lambda p: None,
          on_modified=lambda p: None,
      )

      task = asyncio.create_task(watcher.start())
      await asyncio.sleep(0.1)

      await watcher.stop()
      await asyncio.wait_for(task, timeout=2.0)  # 정상 종료 확인
  ```

### 3.4 성능

- [ ] **RED**: `test_detection_latency` - 감지 지연 < 100ms
  ```python
  async def test_detection_latency(tmp_path):
      import time
      detected = asyncio.Event()
      detection_time = None

      async def on_created(path):
          nonlocal detection_time
          detection_time = time.perf_counter()
          detected.set()

      watcher = WatchfilesWatcher(
          watch_path=str(tmp_path),
          on_created=on_created,
          on_modified=lambda p: None,
      )

      task = asyncio.create_task(watcher.start())
      await asyncio.sleep(0.1)

      start_time = time.perf_counter()
      (tmp_path / "test.json").write_text("{}")

      await asyncio.wait_for(detected.wait(), timeout=5.0)
      latency_ms = (detection_time - start_time) * 1000

      await watcher.stop()
      assert latency_ms < 100  # 100ms 이내
  ```

---

## Phase 4: SyncService (TDD)

**파일**: `src/sync_agent/sync_service.py`
**테스트**: `tests/test_sync_service.py`

### 4.1 실시간 경로

- [ ] **RED**: `test_sync_file_created_immediate` - 생성 파일 즉시 동기화
  ```python
  async def test_sync_file_created_immediate(sync_service, mock_supabase):
      await sync_service.sync_file("/path/test.json", "created")
      mock_supabase.upsert.assert_called_once()
  ```

### 4.2 배치 경로

- [ ] **RED**: `test_sync_file_modified_batched` - 수정 파일 배치 처리
  ```python
  async def test_sync_file_modified_batched(sync_service, mock_supabase):
      await sync_service.sync_file("/path/test.json", "modified")
      mock_supabase.upsert.assert_not_called()  # 아직 배치 안됨
      assert sync_service.batch_queue.pending_count == 1
  ```

- [ ] **RED**: `test_batch_flush_triggers_upsert` - 배치 플러시 시 upsert
  ```python
  async def test_batch_flush_triggers_upsert(sync_service, mock_supabase):
      for i in range(3):
          await sync_service.sync_file(f"/path/{i}.json", "modified")

      await sync_service.flush_batch_queue()
      mock_supabase.upsert.assert_called_once()
  ```

### 4.3 오프라인 큐

- [ ] **RED**: `test_network_failure_queues_locally` - 네트워크 실패 시 로컬 큐
  ```python
  async def test_network_failure_queues_locally(sync_service, mock_supabase):
      mock_supabase.upsert.side_effect = Exception("Network error")
      await sync_service.sync_file("/path/test.json", "created")
      count = await sync_service.local_queue.get_pending_count()
      assert count == 1
  ```

- [ ] **RED**: `test_process_offline_queue` - 오프라인 큐 처리
  ```python
  async def test_process_offline_queue(sync_service, mock_supabase):
      await sync_service.local_queue.enqueue({"id": 1}, "/path/1.json")
      await sync_service.process_offline_queue()
      mock_supabase.upsert.assert_called_once()
  ```

### 4.4 중복 처리

- [ ] **RED**: `test_upsert_handles_duplicate` - 중복 file_hash upsert
  ```python
  async def test_upsert_handles_duplicate(sync_service, mock_supabase):
      # 동일 파일 2번 동기화 - 에러 없이 처리
      await sync_service.sync_file("/path/test.json", "created")
      await sync_service.sync_file("/path/test.json", "created")
      assert mock_supabase.upsert.call_count == 2
  ```

---

## Phase 5: Integration (E2E)

**파일**: `tests/test_integration.py`

### 5.1 전체 플로우

- [ ] **RED**: `test_end_to_end_sync` - 파일 생성 → Supabase 동기화
  ```python
  async def test_end_to_end_sync(tmp_path, mock_supabase):
      settings = SyncAgentSettings(
          gfx_watch_path=str(tmp_path),
          supabase_url="https://test.supabase.co",
          supabase_key="test-key",
      )
      agent = SyncAgent(settings)

      task = asyncio.create_task(agent.start())
      await asyncio.sleep(0.2)

      # 파일 생성
      (tmp_path / "session_001.json").write_text('{"session_id": 1}')
      await asyncio.sleep(1.0)

      await agent.stop()
      mock_supabase.upsert.assert_called()
  ```

### 5.2 장애 복구

- [ ] **RED**: `test_offline_recovery` - 오프라인 → 복구 후 동기화
  ```python
  async def test_offline_recovery(tmp_path, mock_supabase):
      # 1. 네트워크 실패 상황 시뮬레이션
      mock_supabase.upsert.side_effect = Exception("Network error")

      settings = SyncAgentSettings(gfx_watch_path=str(tmp_path))
      agent = SyncAgent(settings)

      task = asyncio.create_task(agent.start())
      await asyncio.sleep(0.2)

      (tmp_path / "session.json").write_text('{"session_id": 1}')
      await asyncio.sleep(0.5)

      # 2. 네트워크 복구
      mock_supabase.upsert.side_effect = None

      # 3. 오프라인 큐 처리 대기
      await asyncio.sleep(2.0)

      await agent.stop()
      # 복구 후 동기화 성공 확인
  ```

### 5.3 성능 검증

- [ ] **RED**: `test_batch_performance` - 100건 배치 < 10초
  ```python
  async def test_batch_performance(sync_service, mock_supabase):
      import time
      start = time.perf_counter()

      for i in range(100):
          await sync_service.sync_file(f"/path/{i}.json", "modified")

      await sync_service.flush_batch_queue()

      elapsed = time.perf_counter() - start
      assert elapsed < 10.0
  ```

---

## 구현 순서

```
┌──────────────────────────────────────────────────────────────┐
│ Phase 1: BatchQueue                                          │
│ ├── test_add_single_record                                   │
│ ├── test_flush_on_max_size                                   │
│ ├── test_manual_flush                                        │
│ ├── test_flush_on_interval                                   │
│ ├── test_concurrent_add                                      │
│ └── test_empty_flush                                         │
└──────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌──────────────────────────────────────────────────────────────┐
│ Phase 2: LocalQueue                                          │
│ ├── test_enqueue                                             │
│ ├── test_dequeue_batch                                       │
│ ├── test_mark_completed                                      │
│ ├── test_mark_failed_increments_retry                        │
│ └── test_persistence                                         │
└──────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌──────────────────────────────────────────────────────────────┐
│ Phase 3: FileWatcher                                         │
│ ├── test_detect_file_created                                 │
│ ├── test_detect_file_modified                                │
│ ├── test_pattern_filter                                      │
│ ├── test_start_stop                                          │
│ └── test_detection_latency                                   │
└──────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌──────────────────────────────────────────────────────────────┐
│ Phase 4: SyncService                                         │
│ ├── test_sync_file_created_immediate                         │
│ ├── test_sync_file_modified_batched                          │
│ ├── test_batch_flush_triggers_upsert                         │
│ ├── test_network_failure_queues_locally                      │
│ ├── test_process_offline_queue                               │
│ └── test_upsert_handles_duplicate                            │
└──────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌──────────────────────────────────────────────────────────────┐
│ Phase 5: Integration                                         │
│ ├── test_end_to_end_sync                                     │
│ ├── test_offline_recovery                                    │
│ └── test_batch_performance                                   │
└──────────────────────────────────────────────────────────────┘
```

---

## Fixtures (conftest.py)

```python
# tests/conftest.py
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock

@pytest.fixture
def mock_supabase():
    """Supabase 클라이언트 Mock."""
    client = MagicMock()
    client.table.return_value.upsert = AsyncMock(return_value={"data": []})
    return client

@pytest.fixture
async def local_queue(tmp_path):
    """임시 LocalQueue."""
    from src.sync_agent.local_queue import LocalQueue
    return LocalQueue(str(tmp_path / "queue.db"))

@pytest.fixture
async def sync_service(mock_supabase, tmp_path):
    """SyncService with mocks."""
    from src.sync_agent.config import SyncAgentSettings
    from src.sync_agent.sync_service import SyncService
    from src.sync_agent.local_queue import LocalQueue

    settings = SyncAgentSettings(
        supabase_url="https://test.supabase.co",
        supabase_key="test-key",
        gfx_watch_path=str(tmp_path),
        batch_size=3,
    )
    local_queue = LocalQueue(str(tmp_path / "queue.db"))
    service = SyncService(settings, local_queue)
    service._supabase = mock_supabase
    return service
```

---

## 실행 명령

```powershell
# 개별 Phase 테스트
pytest tests/test_batch_queue.py -v
pytest tests/test_local_queue.py -v
pytest tests/test_file_watcher.py -v
pytest tests/test_sync_service.py -v
pytest tests/test_integration.py -v

# 전체 테스트 + 커버리지
pytest tests/ -v --cov=src/sync_agent --cov-report=html
```
